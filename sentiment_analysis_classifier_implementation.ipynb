{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>name</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>imageURLs</th>\n",
       "      <th>keys</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.didPurchase</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sourceURLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>... 3 of them and one of the item is bad quali...</td>\n",
       "      <td>Byger yang</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>... always the less expensive way to go for pr...</td>\n",
       "      <td>ByMG</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>... are not Duracell but for the price i am ha...</td>\n",
       "      <td>BySharon Lambert</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id             dateAdded           dateUpdated  \\\n",
       "0  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "1  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "2  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "\n",
       "                                                name                  asins  \\\n",
       "0  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "1  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "2  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "\n",
       "          brand                                         categories  \\\n",
       "0  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "1  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "2  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "\n",
       "  primaryCategories                                          imageURLs  \\\n",
       "0   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "1   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "2   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "\n",
       "                                                keys  ... reviews.didPurchase  \\\n",
       "0  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "1  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "2  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "\n",
       "  reviews.doRecommend reviews.id reviews.numHelpful reviews.rating  \\\n",
       "0                 NaN        NaN                NaN              3   \n",
       "1                 NaN        NaN                NaN              4   \n",
       "2                 NaN        NaN                NaN              5   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "1  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "2  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  I order 3 of them and one of the item is bad q...   \n",
       "1  Bulk is always the less expensive way to go fo...   \n",
       "2  Well they are not Duracell but for the price i...   \n",
       "\n",
       "                                       reviews.title  reviews.username  \\\n",
       "0  ... 3 of them and one of the item is bad quali...        Byger yang   \n",
       "1  ... always the less expensive way to go for pr...              ByMG   \n",
       "2  ... are not Duracell but for the price i am ha...  BySharon Lambert   \n",
       "\n",
       "                                          sourceURLs  \n",
       "0  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "1  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "2  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>... 3 of them and one of the item is bad quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>... always the less expensive way to go for pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>... are not Duracell but for the price i am ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>... as well as name brand batteries at a much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>... batteries are very long lasting the price ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews.rating                                       reviews.text  \\\n",
       "0               3  I order 3 of them and one of the item is bad q...   \n",
       "1               4  Bulk is always the less expensive way to go fo...   \n",
       "2               5  Well they are not Duracell but for the price i...   \n",
       "3               5  Seem to work as well as name brand batteries a...   \n",
       "4               5  These batteries are very long lasting the pric...   \n",
       "\n",
       "                                       reviews.title  \n",
       "0  ... 3 of them and one of the item is bad quali...  \n",
       "1  ... always the less expensive way to go for pr...  \n",
       "2  ... are not Duracell but for the price i am ha...  \n",
       "3  ... as well as name brand batteries at a much ...  \n",
       "4  ... batteries are very long lasting the price ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data = data[['reviews.rating', 'reviews.text', 'reviews.title']]\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>... 3 of them and one of the item is bad quali...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>... always the less expensive way to go for pr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>... are not Duracell but for the price i am ha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>... as well as name brand batteries at a much ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>... batteries are very long lasting the price ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews.rating                                       reviews.text  \\\n",
       "0               3  I order 3 of them and one of the item is bad q...   \n",
       "1               4  Bulk is always the less expensive way to go fo...   \n",
       "2               5  Well they are not Duracell but for the price i...   \n",
       "3               5  Seem to work as well as name brand batteries a...   \n",
       "4               5  These batteries are very long lasting the pric...   \n",
       "\n",
       "                                       reviews.title sentiment_label  \n",
       "0  ... 3 of them and one of the item is bad quali...         Neutral  \n",
       "1  ... always the less expensive way to go for pr...        Positive  \n",
       "2  ... are not Duracell but for the price i am ha...        Positive  \n",
       "3  ... as well as name brand batteries at a much ...        Positive  \n",
       "4  ... batteries are very long lasting the price ...        Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## prepare data\n",
    "def sentiment_labeler(score):\n",
    "    if (score==5) or (score==4):\n",
    "        return \"Positive\"\n",
    "    elif (score==3):\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "    \n",
    "sentiment_data[\"sentiment_label\"]=sentiment_data[\"reviews.rating\"].apply(sentiment_labeler)\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare train, test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up stanfordcorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper function to extract pos tag features\n",
    "\n",
    "def extract_POS(statements):\n",
    "    print('Extracting POS Tags')\n",
    "    pos_tags = POS_tagging(statements,return_word_tag_pairs=False)\n",
    "    bigrams_pos = POS_groupping(pos_tags, grams=2)\n",
    "    trigrams_pos =POS_groupping(pos_tags, grams=3)\n",
    "    print('Finished')\n",
    "    return pos_tags,bigrams_pos,trigrams_pos\n",
    "\n",
    "##\n",
    "def POS_tagging(statements, return_word_tag_pairs = False):\n",
    "    core_nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "    print(\"NLP_Task ready to use.\")\n",
    "    POS_tags = list()\n",
    "    for statement in statements:\n",
    "        statement_tags = list()\n",
    "        annotations = core_nlp.annotate(statement, properties={\n",
    "            'annotators': 'tokenize,pos',\n",
    "            'outputFormat': 'json'\n",
    "            })\n",
    "        for output in annotations['sentences']:\n",
    "            statement_tags.append('<s>')\n",
    "            previous = ''\n",
    "            for token in output['tokens']:\n",
    "                if return_word_tag_pairs:\n",
    "                    statement_tags.append(token['word']+'/'+token['pos'])\n",
    "                else:\n",
    "                    statement_tags.append(token['pos'])\n",
    "\n",
    "        POS_tags.append(statement_tags)\n",
    "    return POS_tags\n",
    "\n",
    "## \n",
    "def POS_groupping(sentences_pos,grams=1):\n",
    "    result = list()\n",
    "    for sentence_tags in sentences_pos:\n",
    "        tag_group = list()\n",
    "        for index, each_tag in enumerate(sentence_tags):\n",
    "            if index < len(sentence_tags)-grams and len(sentence_tags)>=grams:\n",
    "                format_str = str()\n",
    "                for i in range(0,grams):\n",
    "                    format_str += sentence_tags[index+i]\n",
    "                    if i<grams-1:\n",
    "                        format_str += '_'\n",
    "                tag_group.append(format_str)\n",
    "        result.append(tag_group)\n",
    "    return result\n",
    "\n",
    "##\n",
    "def RemoveConsecutiveTags(list_to_remove, postags,ignore_punctuation=False):\n",
    "    withoutConsecutiveTags = list()\n",
    "    for each_tag in postags:\n",
    "        removed = list()\n",
    "        previous = ''\n",
    "        for tt in each_tag:\n",
    "            if tt != previous:\n",
    "                if not ignore_punctuation:\n",
    "                    removed.append(tt)\n",
    "                elif tt not in string.punctuation:\n",
    "                    removed.append(tt)\n",
    "                previous = tt\n",
    "            elif tt not in list_to_remove:\n",
    "                removed.append(tt)\n",
    "                previous = tt\n",
    "        withoutConsecutiveTags.append(removed)\n",
    "    return withoutConsecutiveTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting POS Tags\n",
      "NLP_Task ready to use.\n",
      "Finished\n",
      "Extracting POS Tags\n",
      "NLP_Task ready to use.\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "## extracting pos-tag features\n",
    "unigram_pos_tr, bigrams_pos_tr, trigram_pos_tr = extract_POS(statements=sentiment_data['reviews.text'])\n",
    "unigram_pos_ts, bigrams_pos_ts, trigram_pos_ts = extract_POS(statements=sentiment_data['reviews.text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove duplicated pos tag\n",
    "\n",
    "# For review data\n",
    "list_to_remove = ['NNP','CD']\n",
    "\n",
    "removed_pos_tr =RemoveConsecutiveTags(list_to_remove,unigram_pos_tr)\n",
    "removed_pos_bigrams_tr = POS_groupping(grams=2,sentences_pos=removed_pos_tr)\n",
    "removed_pos_trigrams_tr = POS_groupping(grams=3,sentences_pos=removed_pos_tr)\n",
    "\n",
    "removed_pos_ts =RemoveConsecutiveTags(list_to_remove,unigram_pos_ts)\n",
    "removed_pos_bigrams_ts = POS_groupping(grams=2,sentences_pos=removed_pos_ts)\n",
    "removed_pos_trigrams_ts = POS_groupping(grams=3,sentences_pos=removed_pos_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>pos_unig_tr</th>\n",
       "      <th>pos_big_tr</th>\n",
       "      <th>pos_trig_tr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>PRP VBP CD IN PRP CC CD IN DT NN VBZ JJ NN .  ...</td>\n",
       "      <td>&lt;s&gt;_PRP PRP_VBP VBP_CD CD_IN IN_PRP PRP_CC CC_...</td>\n",
       "      <td>&lt;s&gt;_PRP_VBP PRP_VBP_CD VBP_CD_IN CD_IN_PRP IN_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>NN VBZ RB DT RBR JJ NN TO VB IN NNS IN DT</td>\n",
       "      <td>&lt;s&gt;_NN NN_VBZ VBZ_RB RB_DT DT_RBR RBR_JJ JJ_NN...</td>\n",
       "      <td>&lt;s&gt;_NN_VBZ NN_VBZ_RB VBZ_RB_DT RB_DT_RBR DT_RB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>RB PRP VBP RB NNP CC IN DT NN FW VBP JJ .</td>\n",
       "      <td>&lt;s&gt;_RB RB_PRP PRP_VBP VBP_RB RB_NNP NNP_CC CC_...</td>\n",
       "      <td>&lt;s&gt;_RB_PRP RB_PRP_VBP PRP_VBP_RB VBP_RB_NNP RB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>NNP TO VB RB RB IN NN NN NNS IN DT RB JJR NN</td>\n",
       "      <td>&lt;s&gt;_NNP NNP_TO TO_VB VB_RB RB_RB RB_IN IN_NN N...</td>\n",
       "      <td>&lt;s&gt;_NNP_TO NNP_TO_VB TO_VB_RB VB_RB_RB RB_RB_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>DT NNS VBP RB JJ VBG DT NN VBZ JJ .</td>\n",
       "      <td>&lt;s&gt;_DT DT_NNS NNS_VBP VBP_RB RB_JJ JJ_VBG VBG_...</td>\n",
       "      <td>&lt;s&gt;_DT_NNS DT_NNS_VBP NNS_VBP_RB VBP_RB_JJ RB_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews     label  \\\n",
       "0  I order 3 of them and one of the item is bad q...   Neutral   \n",
       "1  Bulk is always the less expensive way to go fo...  Positive   \n",
       "2  Well they are not Duracell but for the price i...  Positive   \n",
       "3  Seem to work as well as name brand batteries a...  Positive   \n",
       "4  These batteries are very long lasting the pric...  Positive   \n",
       "\n",
       "   reviews.rating                                        pos_unig_tr  \\\n",
       "0               3  PRP VBP CD IN PRP CC CD IN DT NN VBZ JJ NN .  ...   \n",
       "1               4          NN VBZ RB DT RBR JJ NN TO VB IN NNS IN DT   \n",
       "2               5          RB PRP VBP RB NNP CC IN DT NN FW VBP JJ .   \n",
       "3               5       NNP TO VB RB RB IN NN NN NNS IN DT RB JJR NN   \n",
       "4               5                DT NNS VBP RB JJ VBG DT NN VBZ JJ .   \n",
       "\n",
       "                                          pos_big_tr  \\\n",
       "0  <s>_PRP PRP_VBP VBP_CD CD_IN IN_PRP PRP_CC CC_...   \n",
       "1  <s>_NN NN_VBZ VBZ_RB RB_DT DT_RBR RBR_JJ JJ_NN...   \n",
       "2  <s>_RB RB_PRP PRP_VBP VBP_RB RB_NNP NNP_CC CC_...   \n",
       "3  <s>_NNP NNP_TO TO_VB VB_RB RB_RB RB_IN IN_NN N...   \n",
       "4  <s>_DT DT_NNS NNS_VBP VBP_RB RB_JJ JJ_VBG VBG_...   \n",
       "\n",
       "                                         pos_trig_tr  \n",
       "0  <s>_PRP_VBP PRP_VBP_CD VBP_CD_IN CD_IN_PRP IN_...  \n",
       "1  <s>_NN_VBZ NN_VBZ_RB VBZ_RB_DT RB_DT_RBR DT_RB...  \n",
       "2  <s>_RB_PRP RB_PRP_VBP PRP_VBP_RB VBP_RB_NNP RB...  \n",
       "3  <s>_NNP_TO NNP_TO_VB TO_VB_RB VB_RB_RB RB_RB_I...  \n",
       "4  <s>_DT_NNS DT_NNS_VBP NNS_VBP_RB VBP_RB_JJ RB_...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_feats= pd.DataFrame()\n",
    "sentiment_feats['reviews'] = sentiment_data['reviews.text']\n",
    "sentiment_feats['label'] = sentiment_data['sentiment_label']\n",
    "sentiment_feats['reviews.rating'] = sentiment_data['reviews.rating']\n",
    "\n",
    "list_to_remove = ['NNP','CD']\n",
    "\n",
    "sentiment_feats['pos_unig_tr'] = pd.Series([\" \".join(x).replace('<s>','').replace('$','dollar').strip() for x in removed_pos_tr])\n",
    "sentiment_feats['pos_big_tr'] = pd.Series([\" \".join(x).replace('$','dollar').strip() for x in removed_pos_bigrams_tr])\n",
    "sentiment_feats['pos_trig_tr'] = pd.Series([\" \".join(x).replace('$','dollar').strip() for x in removed_pos_trigrams_tr])\n",
    "sentiment_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def GetFeaturesFromPOS(training_data, user_defined_vocabulary=None):\n",
    "    user_defined_vocabulary = [x.lower().replace('$','dollar') for x in user_defined_vocabulary]\n",
    "\n",
    "    # making string of the data\n",
    "    training_str = [\" \".join(x) for x in training_data]\n",
    "\n",
    "    #replace $ by dollar\n",
    "    training_str = [x.replace('$', 'dollar').replace('<s>','sos') for x in training_str]\n",
    "\n",
    "    # features using binary iformation\n",
    "    oneHotVectorizer = CountVectorizer(vocabulary=user_defined_vocabulary,binary=True)\n",
    "    tr_onehot = oneHotVectorizer.fit_transform(training_str).toarray()\n",
    "    print(oneHotVectorizer.vocabulary_)\n",
    "\n",
    "    # features using no-binary information (counting)\n",
    "    countVectorizer = CountVectorizer(vocabulary=user_defined_vocabulary,binary=True)\n",
    "    tr_count = countVectorizer.fit_transform(training_str).toarray()\n",
    "\n",
    "    # features using tf-idf vectors\n",
    "    tfIdfVectorizer = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "    tr_tfidf = tfIdfVectorizer.fit_transform(tr_count)\n",
    "\n",
    "    return tr_onehot, tr_count, tr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vbz': 0, 'dt': 1, 'nnps': 2, 'vbp': 3, 'jj': 4, 'in': 5, 'wrb': 6, 'vbd': 7, 'prp': 8, 'rp': 9, 'wdt': 10, 'vb': 11, 'nnp': 12, 'vbg': 13, 'prpdollar': 14, 'vbn': 15, 'cd': 16, 'rb': 17, 'wp': 18, 'jjs': 19, 'jjr': 20, 'ex': 21, 'rbs': 22, 'fw': 23, 'ls': 24}\n",
      "{'nnps_vbp': 0, 'vb_nnp': 1, 'in_dt': 2, 'vb_jj': 3, 'jj_cd': 4, 'cd_nns': 5, 'dt_jjs': 6, 'jjr_in': 7, 'in_cd': 8, 'cc_in': 9, 'rb_vbd': 10, 'cd_nn': 11, 'nn_to': 12, 'jjr_jj': 13, 'vb_cd': 14}\n",
      "{'vbd_vbn_in': 0, 'in_dt_jj': 1, 'cd_nn_in': 2, 'in_cd_nns': 3, 'in_dt_nn': 4, 'dt_jj_cd': 5, 'md_vb_in': 6, 'jjs_jj_nn': 7, 'cc_jj_nns': 8, 'jj_nns_vbp': 9, 'vbp_cd_nn': 10, 'sos_jjr_in': 11, 'in_dt_nns': 12, 'jj_nn_md': 13}\n"
     ]
    }
   ],
   "source": [
    "pos_relevant_unigrams =  ['VBZ', 'DT', 'NNPS', 'VBP', 'JJ', 'IN', 'WRB', 'VBD', 'PRP', 'RP', 'WDT', 'VB', 'NNP', 'VBG', 'PRP$', 'VBN', 'CD', 'RB', 'WP', 'JJS', 'JJR', 'EX', 'RBS', 'FW', 'LS'] \n",
    "amazonRev_onehot_unigram_tr, amazonRev_count_unigram_tr, amazonRev_tfidf_unigram_tr = GetFeaturesFromPOS(training_data=removed_pos_tr, user_defined_vocabulary=pos_relevant_unigrams)\n",
    "\n",
    "pos_relevant_bigrams = ['NNPS_VBP', 'VB_NNP', 'IN_DT', 'VB_JJ', 'JJ_CD', 'CD_NNS', 'DT_JJS', 'JJR_IN', 'IN_CD', 'CC_IN', 'RB_VBD', 'CD_NN', 'NN_TO', 'JJR_JJ', 'VB_CD'] \n",
    "amazonRev_onehot_bigram_tr, amazonRev_count_bigram_tr, amazonRev_tfidf_bigram_tr = GetFeaturesFromPOS(training_data=removed_pos_bigrams_tr, user_defined_vocabulary=pos_relevant_bigrams)\n",
    "\n",
    "pos_relevant_trigrams = ['VBD_VBN_IN', 'IN_DT_JJ', 'CD_NN_IN', 'IN_CD_NNS', 'IN_DT_NN', 'DT_JJ_CD', 'MD_VB_IN', 'JJS_JJ_NN', 'CC_JJ_NNS', 'JJ_NNS_VBP', 'VBP_CD_NN', 'sos_JJR_IN', 'IN_DT_NNS','JJ_NN_MD']\n",
    "amazonRev_onehot_trigram_tr, amazonRev_count_trigram_tr, amazonRev_tfidf_trigram_tr = GetFeaturesFromPOS(training_data=removed_pos_trigrams_tr, user_defined_vocabulary=pos_relevant_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>pos_unig_tr</th>\n",
       "      <th>pos_big_tr</th>\n",
       "      <th>pos_trig_tr</th>\n",
       "      <th>pos_unigrams_1hot_tr</th>\n",
       "      <th>pos_bigrams_1hot_tr</th>\n",
       "      <th>pos_trigrams_1hot_tr</th>\n",
       "      <th>pos_unigrams_count_tr</th>\n",
       "      <th>pos_bigrams_count_tr</th>\n",
       "      <th>pos_trigrams_count_tr</th>\n",
       "      <th>pos_unigrams_tfidf_tr</th>\n",
       "      <th>pos_bigrams_tfidf_tr</th>\n",
       "      <th>pos_trigrams_tfidf_tr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>PRP VBP CD IN PRP CC CD IN DT NN VBZ JJ NN .  ...</td>\n",
       "      <td>&lt;s&gt;_PRP PRP_VBP VBP_CD CD_IN IN_PRP PRP_CC CC_...</td>\n",
       "      <td>&lt;s&gt;_PRP_VBP PRP_VBP_CD VBP_CD_IN CD_IN_PRP IN_...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 16)\\t0.468652052876125\\n  (0, 13)\\t0.457...</td>\n",
       "      <td>(0, 12)\\t0.8773340588158026\\n  (0, 2)\\t0.479...</td>\n",
       "      <td>(0, 4)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>NN VBZ RB DT RBR JJ NN TO VB IN NNS IN DT</td>\n",
       "      <td>&lt;s&gt;_NN NN_VBZ VBZ_RB RB_DT DT_RBR RBR_JJ JJ_NN...</td>\n",
       "      <td>&lt;s&gt;_NN_VBZ NN_VBZ_RB VBZ_RB_DT RB_DT_RBR DT_RB...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 17)\\t0.4098436732684944\\n  (0, 11)\\t0.45...</td>\n",
       "      <td>(0, 12)\\t1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>RB PRP VBP RB NNP CC IN DT NN FW VBP JJ .</td>\n",
       "      <td>&lt;s&gt;_RB RB_PRP PRP_VBP VBP_RB RB_NNP NNP_CC CC_...</td>\n",
       "      <td>&lt;s&gt;_RB_PRP RB_PRP_VBP PRP_VBP_RB VBP_RB_NNP RB...</td>\n",
       "      <td>[0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 23)\\t0.7435935756396004\\n  (0, 17)\\t0.23...</td>\n",
       "      <td>(0, 9)\\t0.9124980165040811\\n  (0, 2)\\t0.4090...</td>\n",
       "      <td>(0, 4)\\t1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>NNP TO VB RB RB IN NN NN NNS IN DT RB JJR NN</td>\n",
       "      <td>&lt;s&gt;_NNP NNP_TO TO_VB VB_RB RB_RB RB_IN IN_NN N...</td>\n",
       "      <td>&lt;s&gt;_NNP_TO NNP_TO_VB TO_VB_RB VB_RB_RB RB_RB_I...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 20)\\t0.6457240570351381\\n  (0, 17)\\t0.31...</td>\n",
       "      <td>(0, 2)\\t1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>DT NNS VBP RB JJ VBG DT NN VBZ JJ .</td>\n",
       "      <td>&lt;s&gt;_DT DT_NNS NNS_VBP VBP_RB RB_JJ JJ_VBG VBG_...</td>\n",
       "      <td>&lt;s&gt;_DT_NNS DT_NNS_VBP NNS_VBP_RB VBP_RB_JJ RB_...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 17)\\t0.34941682605529095\\n  (0, 13)\\t0.5...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews     label  \\\n",
       "0  I order 3 of them and one of the item is bad q...   Neutral   \n",
       "1  Bulk is always the less expensive way to go fo...  Positive   \n",
       "2  Well they are not Duracell but for the price i...  Positive   \n",
       "3  Seem to work as well as name brand batteries a...  Positive   \n",
       "4  These batteries are very long lasting the pric...  Positive   \n",
       "\n",
       "   reviews.rating                                        pos_unig_tr  \\\n",
       "0               3  PRP VBP CD IN PRP CC CD IN DT NN VBZ JJ NN .  ...   \n",
       "1               4          NN VBZ RB DT RBR JJ NN TO VB IN NNS IN DT   \n",
       "2               5          RB PRP VBP RB NNP CC IN DT NN FW VBP JJ .   \n",
       "3               5       NNP TO VB RB RB IN NN NN NNS IN DT RB JJR NN   \n",
       "4               5                DT NNS VBP RB JJ VBG DT NN VBZ JJ .   \n",
       "\n",
       "                                          pos_big_tr  \\\n",
       "0  <s>_PRP PRP_VBP VBP_CD CD_IN IN_PRP PRP_CC CC_...   \n",
       "1  <s>_NN NN_VBZ VBZ_RB RB_DT DT_RBR RBR_JJ JJ_NN...   \n",
       "2  <s>_RB RB_PRP PRP_VBP VBP_RB RB_NNP NNP_CC CC_...   \n",
       "3  <s>_NNP NNP_TO TO_VB VB_RB RB_RB RB_IN IN_NN N...   \n",
       "4  <s>_DT DT_NNS NNS_VBP VBP_RB RB_JJ JJ_VBG VBG_...   \n",
       "\n",
       "                                         pos_trig_tr  \\\n",
       "0  <s>_PRP_VBP PRP_VBP_CD VBP_CD_IN CD_IN_PRP IN_...   \n",
       "1  <s>_NN_VBZ NN_VBZ_RB VBZ_RB_DT RB_DT_RBR DT_RB...   \n",
       "2  <s>_RB_PRP RB_PRP_VBP PRP_VBP_RB VBP_RB_NNP RB...   \n",
       "3  <s>_NNP_TO NNP_TO_VB TO_VB_RB VB_RB_RB RB_RB_I...   \n",
       "4  <s>_DT_NNS DT_NNS_VBP NNS_VBP_RB VBP_RB_JJ RB_...   \n",
       "\n",
       "                                pos_unigrams_1hot_tr  \\\n",
       "0  [1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...   \n",
       "1  [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "4  [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "\n",
       "                             pos_bigrams_1hot_tr  \\\n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "2  [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                         pos_trigrams_1hot_tr  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                               pos_unigrams_count_tr  \\\n",
       "0  [1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...   \n",
       "1  [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "4  [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "\n",
       "                            pos_bigrams_count_tr  \\\n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "2  [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                        pos_trigrams_count_tr  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                               pos_unigrams_tfidf_tr  \\\n",
       "0    (0, 16)\\t0.468652052876125\\n  (0, 13)\\t0.457...   \n",
       "1    (0, 17)\\t0.4098436732684944\\n  (0, 11)\\t0.45...   \n",
       "2    (0, 23)\\t0.7435935756396004\\n  (0, 17)\\t0.23...   \n",
       "3    (0, 20)\\t0.6457240570351381\\n  (0, 17)\\t0.31...   \n",
       "4    (0, 17)\\t0.34941682605529095\\n  (0, 13)\\t0.5...   \n",
       "\n",
       "                                pos_bigrams_tfidf_tr pos_trigrams_tfidf_tr  \n",
       "0    (0, 12)\\t0.8773340588158026\\n  (0, 2)\\t0.479...           (0, 4)\\t1.0  \n",
       "1                                       (0, 12)\\t1.0                        \n",
       "2    (0, 9)\\t0.9124980165040811\\n  (0, 2)\\t0.4090...           (0, 4)\\t1.0  \n",
       "3                                        (0, 2)\\t1.0                        \n",
       "4                                                                           "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentiment_feats['pos_unigrams_1hot_tr'] =  pd.Series([np.array(x) for x in amazonRev_onehot_unigram_tr])\n",
    "sentiment_feats['pos_bigrams_1hot_tr'] = pd.Series([np.array(x) for x in amazonRev_onehot_bigram_tr])\n",
    "sentiment_feats['pos_trigrams_1hot_tr'] = pd.Series([np.array(x) for x in amazonRev_onehot_trigram_tr])\n",
    "\n",
    "sentiment_feats['pos_unigrams_count_tr'] = pd.Series([np.array(x) for x in amazonRev_count_unigram_tr])\n",
    "sentiment_feats['pos_bigrams_count_tr'] = pd.Series([np.array(x) for x in amazonRev_count_bigram_tr])\n",
    "sentiment_feats['pos_trigrams_count_tr'] = pd.Series([np.array(x) for x in amazonRev_count_trigram_tr])\n",
    "\n",
    "sentiment_feats['pos_unigrams_tfidf_tr'] =  pd.Series([np.array(x) for x in amazonRev_tfidf_unigram_tr])\n",
    "sentiment_feats['pos_bigrams_tfidf_tr'] = pd.Series([np.array(x) for x in amazonRev_tfidf_bigram_tr])\n",
    "sentiment_feats['pos_trigrams_tfidf_tr'] = pd.Series([np.array(x) for x in amazonRev_tfidf_trigram_tr])\n",
    "\n",
    "sentiment_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>pos_unig_tr</th>\n",
       "      <th>pos_big_tr</th>\n",
       "      <th>pos_trig_tr</th>\n",
       "      <th>pos_unigrams_1hot_tr</th>\n",
       "      <th>pos_bigrams_1hot_tr</th>\n",
       "      <th>pos_trigrams_1hot_tr</th>\n",
       "      <th>pos_unigrams_count_tr</th>\n",
       "      <th>pos_bigrams_count_tr</th>\n",
       "      <th>pos_trigrams_count_tr</th>\n",
       "      <th>pos_unigrams_tfidf_tr</th>\n",
       "      <th>pos_bigrams_tfidf_tr</th>\n",
       "      <th>pos_trigrams_tfidf_tr</th>\n",
       "      <th>pos_unigrams_tfidf</th>\n",
       "      <th>pos_bigrams_tfidf</th>\n",
       "      <th>pos_trigrams_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>PRP VBP CD IN PRP CC CD IN DT NN VBZ JJ NN .  ...</td>\n",
       "      <td>&lt;s&gt;_PRP PRP_VBP VBP_CD CD_IN IN_PRP PRP_CC CC_...</td>\n",
       "      <td>&lt;s&gt;_PRP_VBP PRP_VBP_CD VBP_CD_IN CD_IN_PRP IN_...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 16)\\t0.468652052876125\\n  (0, 13)\\t0.457...</td>\n",
       "      <td>(0, 12)\\t0.8773340588158026\\n  (0, 2)\\t0.479...</td>\n",
       "      <td>(0, 4)\\t1.0</td>\n",
       "      <td>[0.33326393978382374, 0.25145369000993206, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.4798801404953009, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>NN VBZ RB DT RBR JJ NN TO VB IN NNS IN DT</td>\n",
       "      <td>&lt;s&gt;_NN NN_VBZ VBZ_RB RB_DT DT_RBR RBR_JJ JJ_NN...</td>\n",
       "      <td>&lt;s&gt;_NN_VBZ NN_VBZ_RB VBZ_RB_DT RB_DT_RBR DT_RB...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 17)\\t0.4098436732684944\\n  (0, 11)\\t0.45...</td>\n",
       "      <td>(0, 12)\\t1.0</td>\n",
       "      <td></td>\n",
       "      <td>[0.49362715060265006, 0.37245064254068355, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>RB PRP VBP RB NNP CC IN DT NN FW VBP JJ .</td>\n",
       "      <td>&lt;s&gt;_RB RB_PRP PRP_VBP VBP_RB RB_NNP NNP_CC CC_...</td>\n",
       "      <td>&lt;s&gt;_RB_PRP RB_PRP_VBP PRP_VBP_RB VBP_RB_NNP RB...</td>\n",
       "      <td>[0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 23)\\t0.7435935756396004\\n  (0, 17)\\t0.23...</td>\n",
       "      <td>(0, 9)\\t0.9124980165040811\\n  (0, 2)\\t0.4090...</td>\n",
       "      <td>(0, 4)\\t1.0</td>\n",
       "      <td>[0.0, 0.21698552304929278, 0.0, 0.294983793842...</td>\n",
       "      <td>[0.0, 0.0, 0.4090811287215748, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>NNP TO VB RB RB IN NN NN NNS IN DT RB JJR NN</td>\n",
       "      <td>&lt;s&gt;_NNP NNP_TO TO_VB VB_RB RB_RB RB_IN IN_NN N...</td>\n",
       "      <td>&lt;s&gt;_NNP_TO NNP_TO_VB TO_VB_RB VB_RB_RB RB_RB_I...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 20)\\t0.6457240570351381\\n  (0, 17)\\t0.31...</td>\n",
       "      <td>(0, 2)\\t1.0</td>\n",
       "      <td></td>\n",
       "      <td>[0.0, 0.2847429487413753, 0.0, 0.0, 0.0, 0.276...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>DT NNS VBP RB JJ VBG DT NN VBZ JJ .</td>\n",
       "      <td>&lt;s&gt;_DT DT_NNS NNS_VBP VBP_RB RB_JJ JJ_VBG VBG_...</td>\n",
       "      <td>&lt;s&gt;_DT_NNS DT_NNS_VBP NNS_VBP_RB VBP_RB_JJ RB_...</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(0, 17)\\t0.34941682605529095\\n  (0, 13)\\t0.5...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[0.4208473705175385, 0.3175369777968061, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews     label  \\\n",
       "0  I order 3 of them and one of the item is bad q...   Neutral   \n",
       "1  Bulk is always the less expensive way to go fo...  Positive   \n",
       "2  Well they are not Duracell but for the price i...  Positive   \n",
       "3  Seem to work as well as name brand batteries a...  Positive   \n",
       "4  These batteries are very long lasting the pric...  Positive   \n",
       "\n",
       "   reviews.rating                                        pos_unig_tr  \\\n",
       "0               3  PRP VBP CD IN PRP CC CD IN DT NN VBZ JJ NN .  ...   \n",
       "1               4          NN VBZ RB DT RBR JJ NN TO VB IN NNS IN DT   \n",
       "2               5          RB PRP VBP RB NNP CC IN DT NN FW VBP JJ .   \n",
       "3               5       NNP TO VB RB RB IN NN NN NNS IN DT RB JJR NN   \n",
       "4               5                DT NNS VBP RB JJ VBG DT NN VBZ JJ .   \n",
       "\n",
       "                                          pos_big_tr  \\\n",
       "0  <s>_PRP PRP_VBP VBP_CD CD_IN IN_PRP PRP_CC CC_...   \n",
       "1  <s>_NN NN_VBZ VBZ_RB RB_DT DT_RBR RBR_JJ JJ_NN...   \n",
       "2  <s>_RB RB_PRP PRP_VBP VBP_RB RB_NNP NNP_CC CC_...   \n",
       "3  <s>_NNP NNP_TO TO_VB VB_RB RB_RB RB_IN IN_NN N...   \n",
       "4  <s>_DT DT_NNS NNS_VBP VBP_RB RB_JJ JJ_VBG VBG_...   \n",
       "\n",
       "                                         pos_trig_tr  \\\n",
       "0  <s>_PRP_VBP PRP_VBP_CD VBP_CD_IN CD_IN_PRP IN_...   \n",
       "1  <s>_NN_VBZ NN_VBZ_RB VBZ_RB_DT RB_DT_RBR DT_RB...   \n",
       "2  <s>_RB_PRP RB_PRP_VBP PRP_VBP_RB VBP_RB_NNP RB...   \n",
       "3  <s>_NNP_TO NNP_TO_VB TO_VB_RB VB_RB_RB RB_RB_I...   \n",
       "4  <s>_DT_NNS DT_NNS_VBP NNS_VBP_RB VBP_RB_JJ RB_...   \n",
       "\n",
       "                                pos_unigrams_1hot_tr  \\\n",
       "0  [1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...   \n",
       "1  [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "4  [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "\n",
       "                             pos_bigrams_1hot_tr  \\\n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "2  [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                         pos_trigrams_1hot_tr  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                               pos_unigrams_count_tr  \\\n",
       "0  [1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, ...   \n",
       "1  [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "2  [0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...   \n",
       "3  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, ...   \n",
       "4  [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "\n",
       "                            pos_bigrams_count_tr  \\\n",
       "0  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]   \n",
       "2  [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                        pos_trigrams_count_tr  \\\n",
       "0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                               pos_unigrams_tfidf_tr  \\\n",
       "0    (0, 16)\\t0.468652052876125\\n  (0, 13)\\t0.457...   \n",
       "1    (0, 17)\\t0.4098436732684944\\n  (0, 11)\\t0.45...   \n",
       "2    (0, 23)\\t0.7435935756396004\\n  (0, 17)\\t0.23...   \n",
       "3    (0, 20)\\t0.6457240570351381\\n  (0, 17)\\t0.31...   \n",
       "4    (0, 17)\\t0.34941682605529095\\n  (0, 13)\\t0.5...   \n",
       "\n",
       "                                pos_bigrams_tfidf_tr pos_trigrams_tfidf_tr  \\\n",
       "0    (0, 12)\\t0.8773340588158026\\n  (0, 2)\\t0.479...           (0, 4)\\t1.0   \n",
       "1                                       (0, 12)\\t1.0                         \n",
       "2    (0, 9)\\t0.9124980165040811\\n  (0, 2)\\t0.4090...           (0, 4)\\t1.0   \n",
       "3                                        (0, 2)\\t1.0                         \n",
       "4                                                                            \n",
       "\n",
       "                                  pos_unigrams_tfidf  \\\n",
       "0  [0.33326393978382374, 0.25145369000993206, 0.0...   \n",
       "1  [0.49362715060265006, 0.37245064254068355, 0.0...   \n",
       "2  [0.0, 0.21698552304929278, 0.0, 0.294983793842...   \n",
       "3  [0.0, 0.2847429487413753, 0.0, 0.0, 0.0, 0.276...   \n",
       "4  [0.4208473705175385, 0.3175369777968061, 0.0, ...   \n",
       "\n",
       "                                   pos_bigrams_tfidf  \\\n",
       "0  [0.0, 0.0, 0.4798801404953009, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.4090811287215748, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                  pos_trigrams_tfidf  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reshape the tfidf vectors so they can be combined\n",
    "sentiment_feats['pos_unigrams_tfidf'] = sentiment_feats['pos_unigrams_tfidf_tr'].apply(lambda x: x.reshape((1,))[0].toarray()[0])\n",
    "sentiment_feats['pos_bigrams_tfidf'] = sentiment_feats['pos_bigrams_tfidf_tr'].apply(lambda x: x.reshape((1,))[0].toarray()[0])\n",
    "sentiment_feats['pos_trigrams_tfidf'] = sentiment_feats['pos_trigrams_tfidf_tr'].apply(lambda x: x.reshape((1,))[0].toarray()[0])\n",
    "\n",
    "sentiment_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunker class to build parse trees\n",
    "\n",
    "import nltk\n",
    "\n",
    "class Chunker():\n",
    "\tdef __init__(self, n):\n",
    "\t\t# Load the corpus to train the chunk tagger\n",
    "\t\tconll = nltk.corpus.conll2000.chunked_sents()\n",
    "\t\ttreebank = nltk.corpus.treebank_chunk.chunked_sents()\n",
    "\t\tdata = conll + treebank\n",
    "\n",
    "\t\tchunks = [ nltk.chunk.tree2conlltags(tree) for tree in data ]\n",
    "\t\tchunks = [ [(tag[1], tag[2]) for tag in tags] for tags in chunks ]\n",
    "\n",
    "\t\ttrain_chunks = chunks\n",
    "\n",
    "\t\t# Train the chunk tagger\n",
    "\t\tself.chunk_tagger = None\n",
    "\t\tif n == \"Unigram\":\n",
    "\t\t\tself.chunk_tagger = nltk.tag.UnigramTagger(train_chunks)\n",
    "\t\telif n == \"Bigram\":\n",
    "\t\t\tself.chunk_tagger = nltk.tag.BigramTagger(train_chunks)\n",
    "\t\telif n == \"Trigram\":\n",
    "\t\t\tself.chunk_tagger = nltk.tag.TrigramTagger(train_chunks)\n",
    "\t\telse:\n",
    "\t\t\tchunker = nltk.tag.UnigramTagger(train_chunks)\n",
    "\t\t\tchunker = nltk.tag.BigramTagger(train_chunks, backoff=chunker)\n",
    "\t\t\tchunker = nltk.tag.TrigramTagger(train_chunks, backoff=chunker)\n",
    "\t\t\tself.chunk_tagger = chunker\n",
    "\n",
    "\tdef parseTree(self, tokens):\n",
    "\t\t# Gather the words, tags, and chunks\n",
    "\t\twords = [w for (w,t) in tokens]\n",
    "\t\ttags = [t for (w,t) in tokens]\n",
    "\t\tchunks = self.chunk_tagger.tag(tags)\n",
    "\n",
    "\t\t# Sanity check\n",
    "\t\tassert len(words) == len(tags)\n",
    "\t\tassert len(words) == len(chunks)\n",
    "\n",
    "\t\t# Build the parse tree\n",
    "\t\tl = []\n",
    "\t\tfor i in range(0,len(words)):\n",
    "\t\t\tif chunks[i][1]:\n",
    "\t\t\t\tl.append( ' '.join([words[i], tags[i], chunks[i][1]]) )\n",
    "\n",
    "\t\treturn nltk.chunk.conllstr2tree('\\n'.join(l))\n",
    "\n",
    "def chunkLabels(tree):\n",
    "\tl = []\n",
    "\tfor t in tree.subtrees():\n",
    "\t\tif t.label() != 'S':\n",
    "\t\t\tl.append(t.label())\n",
    "\treturn ' '.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uni_chunk_labels</th>\n",
       "      <th>bi_chunk_labels</th>\n",
       "      <th>tri_chunk_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NP PP NP NP NP VP NP VP NP NP VP NP PP NP PP N...</td>\n",
       "      <td>NP PP NP NP NP VP NP VP NP NP VP NP PP NP PP N...</td>\n",
       "      <td>NP PP NP NP NP VP NP VP NP NP VP NP PP NP PP N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NP VP NP NP PP NP PP NP PP NP</td>\n",
       "      <td>NP VP NP NP PP NP PP NP PP NP</td>\n",
       "      <td>NP VP NP NP PP NP PP NP PP NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NP VP NP NP VP NP</td>\n",
       "      <td>NP VP NP NP VP NP</td>\n",
       "      <td>NP VP NP NP VP NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NP VP NP PP NP NP</td>\n",
       "      <td>NP VP NP PP NP NP</td>\n",
       "      <td>NP VP NP PP NP NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NP VP VP NP VP</td>\n",
       "      <td>NP VP VP NP VP</td>\n",
       "      <td>NP VP VP NP VP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uni_chunk_labels  \\\n",
       "0  NP PP NP NP NP VP NP VP NP NP VP NP PP NP PP N...   \n",
       "1                      NP VP NP NP PP NP PP NP PP NP   \n",
       "2                                  NP VP NP NP VP NP   \n",
       "3                                  NP VP NP PP NP NP   \n",
       "4                                     NP VP VP NP VP   \n",
       "\n",
       "                                     bi_chunk_labels  \\\n",
       "0  NP PP NP NP NP VP NP VP NP NP VP NP PP NP PP N...   \n",
       "1                      NP VP NP NP PP NP PP NP PP NP   \n",
       "2                                  NP VP NP NP VP NP   \n",
       "3                                  NP VP NP PP NP NP   \n",
       "4                                     NP VP VP NP VP   \n",
       "\n",
       "                                    tri_chunk_labels  \n",
       "0  NP PP NP NP NP VP NP VP NP NP VP NP PP NP PP N...  \n",
       "1                      NP VP NP NP PP NP PP NP PP NP  \n",
       "2                                  NP VP NP NP VP NP  \n",
       "3                                  NP VP NP PP NP NP  \n",
       "4                                     NP VP VP NP VP  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Parse into chunks and extract chunk labels\n",
    "\n",
    "ch_unigram = Chunker('unigram')\n",
    "ch_bigram = Chunker('bigram')\n",
    "ch_trigram = Chunker('trigram')\n",
    "\n",
    "sentiment_feats['uni_chunk_labels'] = sentiment_feats['reviews'].apply(str.split)\n",
    "sentiment_feats['uni_chunk_labels'] = sentiment_feats['uni_chunk_labels'].apply(nltk.pos_tag)\n",
    "sentiment_feats['uni_chunk_labels'] = sentiment_feats['uni_chunk_labels'].apply(ch_unigram.parseTree)\n",
    "sentiment_feats['uni_chunk_labels'] = sentiment_feats['uni_chunk_labels'].apply(chunkLabels)\n",
    "\n",
    "sentiment_feats['bi_chunk_labels'] = sentiment_feats['reviews'].apply(str.split)\n",
    "sentiment_feats['bi_chunk_labels'] = sentiment_feats['bi_chunk_labels'].apply(nltk.pos_tag)\n",
    "sentiment_feats['bi_chunk_labels'] = sentiment_feats['bi_chunk_labels'].apply(ch_bigram.parseTree)\n",
    "sentiment_feats['bi_chunk_labels'] = sentiment_feats['bi_chunk_labels'].apply(chunkLabels)\n",
    "\n",
    "sentiment_feats['tri_chunk_labels'] = sentiment_feats['reviews'].apply(str.split)\n",
    "sentiment_feats['tri_chunk_labels'] = sentiment_feats['tri_chunk_labels'].apply(nltk.pos_tag)\n",
    "sentiment_feats['tri_chunk_labels'] = sentiment_feats['tri_chunk_labels'].apply(ch_trigram.parseTree)\n",
    "sentiment_feats['tri_chunk_labels'] = sentiment_feats['tri_chunk_labels'].apply(chunkLabels)\n",
    "\n",
    "sentiment_feats[['uni_chunk_labels', 'bi_chunk_labels', 'tri_chunk_labels']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countChunks(data):\n",
    "    tokens = data.split()\n",
    "    vocabulary = ['NP', 'VP', 'PP']\n",
    "    counts = [0, 0, 0, 0]\n",
    "    for t in tokens:\n",
    "        if t == vocabulary[0]:\n",
    "            counts[0] = counts[0] + 1\n",
    "        elif t == vocabulary[1]:\n",
    "            counts[1] = counts[1] + 1\n",
    "        elif t == vocabulary[2]:\n",
    "            counts[2] = counts[2] + 1\n",
    "        else:\n",
    "            counts[3] = counts[3] + 1\n",
    "    return np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uni_chunk_counts</th>\n",
       "      <th>bi_chunk_counts</th>\n",
       "      <th>tri_chunk_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[11, 3, 3, 0]</td>\n",
       "      <td>[11, 3, 3, 0]</td>\n",
       "      <td>[11, 3, 3, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6, 1, 3, 0]</td>\n",
       "      <td>[6, 1, 3, 0]</td>\n",
       "      <td>[6, 1, 3, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4, 2, 0, 0]</td>\n",
       "      <td>[4, 2, 0, 0]</td>\n",
       "      <td>[4, 2, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4, 1, 1, 0]</td>\n",
       "      <td>[4, 1, 1, 0]</td>\n",
       "      <td>[4, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 3, 0, 0]</td>\n",
       "      <td>[2, 3, 0, 0]</td>\n",
       "      <td>[2, 3, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uni_chunk_counts bi_chunk_counts tri_chunk_counts\n",
       "0    [11, 3, 3, 0]   [11, 3, 3, 0]    [11, 3, 3, 0]\n",
       "1     [6, 1, 3, 0]    [6, 1, 3, 0]     [6, 1, 3, 0]\n",
       "2     [4, 2, 0, 0]    [4, 2, 0, 0]     [4, 2, 0, 0]\n",
       "3     [4, 1, 1, 0]    [4, 1, 1, 0]     [4, 1, 1, 0]\n",
       "4     [2, 3, 0, 0]    [2, 3, 0, 0]     [2, 3, 0, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count the chunk occurrences\n",
    "## unigram, bigram, and trigram may be redundant here.  They all look the same.\n",
    "sentiment_feats['uni_chunk_counts'] = sentiment_feats['uni_chunk_labels'].apply(countChunks)\n",
    "sentiment_feats['bi_chunk_counts'] = sentiment_feats['bi_chunk_labels'].apply(countChunks)\n",
    "sentiment_feats['tri_chunk_counts'] = sentiment_feats['tri_chunk_labels'].apply(countChunks)\n",
    "sentiment_feats[['uni_chunk_counts', 'bi_chunk_counts', 'tri_chunk_counts']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim pos_unigrams_1hot_tr:\t (25,)\n",
      "dim pos_bigrams_1hot_tr:\t (15,)\n",
      "dim pos_trigrams_1hot_tr:\t (14,)\n",
      "dim pos_unigrams_count_tr:\t (25,)\n",
      "dim pos_bigrams_count_tr:\t (15,)\n",
      "dim pos_trigrams_count_tr:\t (14,)\n",
      "dim pos_unigrams_tfidf:\t (25,)\n",
      "dim pos_bigrams_tfidf:\t (15,)\n",
      "dim pos_trigrams_tfidf:\t (14,)\n",
      "dim uni_chunk_counts:\t (4,)\n",
      "dim bi_chunk_counts:\t (4,)\n",
      "dim tri_chunk_counts:\t (4,)\n",
      "dim combined:\t\t\t (174,)\n"
     ]
    }
   ],
   "source": [
    "## Combine all the features\n",
    "combined_feats = ['pos_unigrams_1hot_tr', 'pos_bigrams_1hot_tr', 'pos_trigrams_1hot_tr', 'pos_unigrams_count_tr','pos_bigrams_count_tr', 'pos_trigrams_count_tr', 'pos_unigrams_tfidf', 'pos_bigrams_tfidf', 'pos_trigrams_tfidf', 'uni_chunk_counts', 'bi_chunk_counts', 'tri_chunk_counts']\n",
    "sentiment_feats['combined'] = sentiment_feats[combined_feats].apply(np.concatenate, axis=1)\n",
    "for x in combined_feats:\n",
    "    print(\"dim \" + x + \":\\t\", sentiment_feats[x].iloc[0].shape)\n",
    "print(\"dim combined:\\t\\t\\t\", sentiment_feats[\"combined\"].iloc[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy metrics for naive bayes classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.33      0.26       316\n",
      "           0       0.15      0.02      0.04       241\n",
      "          -1       0.92      0.93      0.92      5110\n",
      "\n",
      "    accuracy                           0.86      5667\n",
      "   macro avg       0.43      0.43      0.41      5667\n",
      "weighted avg       0.85      0.86      0.85      5667\n",
      "\n",
      "======================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy metrics for logistic regression classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.06      0.11       316\n",
      "           0       0.00      0.00      0.00       241\n",
      "          -1       0.91      1.00      0.95      5110\n",
      "\n",
      "    accuracy                           0.90      5667\n",
      "   macro avg       0.46      0.35      0.35      5667\n",
      "weighted avg       0.84      0.90      0.86      5667\n",
      "\n",
      "======================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy metrics for linear SVM classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.01      0.02       316\n",
      "           0       0.00      0.00      0.00       241\n",
      "          -1       0.90      1.00      0.95      5110\n",
      "\n",
      "    accuracy                           0.90      5667\n",
      "   macro avg       0.40      0.34      0.32      5667\n",
      "weighted avg       0.83      0.90      0.86      5667\n",
      "\n",
      "======================================================================================\n",
      "accuracy metrics for random forest classifier:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.38      0.48       316\n",
      "           0       0.77      0.39      0.51       241\n",
      "          -1       0.94      0.99      0.96      5110\n",
      "\n",
      "    accuracy                           0.93      5667\n",
      "   macro avg       0.79      0.58      0.65      5667\n",
      "weighted avg       0.92      0.93      0.92      5667\n",
      "\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split_data=StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n",
    "for tr_indx, ts_indx in split_data.split(sentiment_feats, sentiment_feats[\"label\"]):\n",
    "    train_data=sentiment_feats.reindex(tr_indx)\n",
    "    test_data=sentiment_feats.reindex(ts_indx)\n",
    "\n",
    "# Set the train and test data\n",
    "X_train = train_data['combined'].tolist()\n",
    "y_train = train_data['label'].tolist()\n",
    "X_test = test_data['combined'].tolist()\n",
    "y_test = test_data['label'].tolist()\n",
    "\n",
    "# Train the classifiers and print results\n",
    "def print_results(name, classifier, X_train, y_train, X_test, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predicted = classifier.predict(X_test)\n",
    "    print(\"accuracy metrics for \" + name + \" classifier:\\n\",metrics.classification_report(y_test, predicted, target_names = ['1','0','-1']))\n",
    "    print(\"======================================================================================\")\n",
    "\n",
    "print_results(\"naive bayes\", MultinomialNB(), X_train, y_train, X_test, y_test)\n",
    "print_results(\"logistic regression\", LogisticRegression(), X_train, y_train, X_test, y_test)    \n",
    "print_results(\"linear SVM\", LinearSVC(), X_train, y_train, X_test, y_test)\n",
    "print_results(\"random forest\", RandomForestClassifier(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "\n",
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('conll2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTextBlobFeatures(corpus):\n",
    "    extractor = ConllExtractor()\n",
    "    text_blob_features = np.zeros((len(corpus),4))\n",
    "    blob_sentiment_analyzer = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "    for i,each_text in enumerate(corpus):\n",
    "        text_blob_features[i,0]=blob_sentiment_analyzer(each_text).sentiment[1]\n",
    "        text_blob_features[i,1]=blob_sentiment_analyzer(each_text).sentiment[2]\n",
    "        text_blob_features[i,2]= TextBlob(each_text).subjectivity\n",
    "        noun_phrase_extractor = TextBlob(each_text, np_extractor=extractor)\n",
    "        text_blob_features[i,3]= len(noun_phrase_extractor.noun_phrases)\n",
    "    return text_blob_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_data['reviews.text']\n",
    "y_train=train_data[\"sentiment_label\"]\n",
    "X_test=test_data[\"reviews.text\"]\n",
    "y_test=test_data[\"sentiment_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_tb_features = extractTextBlobFeatures(X_train)\n",
    "Xte_tb_features = extractTextBlobFeatures(X_test)\n",
    "ytr_tb_features = extractTextBlobFeatures(y_train)\n",
    "yte_tb_features = extractTextBlobFeatures(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_tb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtr= np.array(Xtr_tb_features.ravel(),)\n",
    "# ytr=np.array(ytr_tb_features.ravel(),)\n",
    "\n",
    "# Xte = np.array(Xte_tb_features.ravel(),)\n",
    "# yte = np.array(yte_tb_features.ravel(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## use multinomial NB classifier\n",
    "# clf_multiNB_pipe = Pipeline([(\"vect\", CountVectorizer()), (\"tfidf\", TfidfTransformer()), (\"clf_nominalNB\", MultinomialNB())])\n",
    "# clf_multiNB_pipe.fit(Xtr, ytr)\n",
    "# predicted_nb = clf_multiNB_pipe.predict(Xte)\n",
    "# print(\"accuracy metrics for training naive bayes classifier:\\n\",metrics.classification_report(yte, predicted_nb, target_names = ['1','0','-1']))\n",
    "# print(\"======================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte_tb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr_tb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
