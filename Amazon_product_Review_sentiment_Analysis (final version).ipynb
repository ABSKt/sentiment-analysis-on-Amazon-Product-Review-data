{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>name</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>imageURLs</th>\n",
       "      <th>keys</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.didPurchase</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.id</th>\n",
       "      <th>reviews.numHelpful</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sourceURLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>... 3 of them and one of the item is bad quali...</td>\n",
       "      <td>Byger yang</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>... always the less expensive way to go for pr...</td>\n",
       "      <td>ByMG</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
       "      <td>2015-10-30T08:59:32Z</td>\n",
       "      <td>2019-04-25T09:08:16Z</td>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>... are not Duracell but for the price i am ha...</td>\n",
       "      <td>BySharon Lambert</td>\n",
       "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id             dateAdded           dateUpdated  \\\n",
       "0  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "1  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "2  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
       "\n",
       "                                                name                  asins  \\\n",
       "0  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "1  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "2  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
       "\n",
       "          brand                                         categories  \\\n",
       "0  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "1  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "2  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
       "\n",
       "  primaryCategories                                          imageURLs  \\\n",
       "0   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "1   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "2   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
       "\n",
       "                                                keys  ... reviews.didPurchase  \\\n",
       "0  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "1  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "2  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
       "\n",
       "  reviews.doRecommend reviews.id reviews.numHelpful reviews.rating  \\\n",
       "0                 NaN        NaN                NaN              3   \n",
       "1                 NaN        NaN                NaN              4   \n",
       "2                 NaN        NaN                NaN              5   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "1  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "2  https://www.amazon.com/product-reviews/B00QWO9...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  I order 3 of them and one of the item is bad q...   \n",
       "1  Bulk is always the less expensive way to go fo...   \n",
       "2  Well they are not Duracell but for the price i...   \n",
       "\n",
       "                                       reviews.title  reviews.username  \\\n",
       "0  ... 3 of them and one of the item is bad quali...        Byger yang   \n",
       "1  ... always the less expensive way to go for pr...              ByMG   \n",
       "2  ... are not Duracell but for the price i am ha...  BySharon Lambert   \n",
       "\n",
       "                                          sourceURLs  \n",
       "0  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "1  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "2  https://www.barcodable.com/upc/841710106442,ht...  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>... 3 of them and one of the item is bad quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>... always the less expensive way to go for pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>... are not Duracell but for the price i am ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>... as well as name brand batteries at a much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>... batteries are very long lasting the price ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews.rating                                       reviews.text  \\\n",
       "0               3  I order 3 of them and one of the item is bad q...   \n",
       "1               4  Bulk is always the less expensive way to go fo...   \n",
       "2               5  Well they are not Duracell but for the price i...   \n",
       "3               5  Seem to work as well as name brand batteries a...   \n",
       "4               5  These batteries are very long lasting the pric...   \n",
       "\n",
       "                                       reviews.title  \n",
       "0  ... 3 of them and one of the item is bad quali...  \n",
       "1  ... always the less expensive way to go for pr...  \n",
       "2  ... are not Duracell but for the price i am ha...  \n",
       "3  ... as well as name brand batteries at a much ...  \n",
       "4  ... batteries are very long lasting the price ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data = data[['reviews.rating', 'reviews.text', 'reviews.title']]\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>... 3 of them and one of the item is bad quali...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>... always the less expensive way to go for pr...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>... are not Duracell but for the price i am ha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>... as well as name brand batteries at a much ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>... batteries are very long lasting the price ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviews.rating                                       reviews.text  \\\n",
       "0               3  I order 3 of them and one of the item is bad q...   \n",
       "1               4  Bulk is always the less expensive way to go fo...   \n",
       "2               5  Well they are not Duracell but for the price i...   \n",
       "3               5  Seem to work as well as name brand batteries a...   \n",
       "4               5  These batteries are very long lasting the pric...   \n",
       "\n",
       "                                       reviews.title sentiment_label  \n",
       "0  ... 3 of them and one of the item is bad quali...         Neutral  \n",
       "1  ... always the less expensive way to go for pr...        Positive  \n",
       "2  ... are not Duracell but for the price i am ha...        Positive  \n",
       "3  ... as well as name brand batteries at a much ...        Positive  \n",
       "4  ... batteries are very long lasting the price ...        Positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## prepare data\n",
    "def sentiment_labeler(score):\n",
    "    if (score==5) or (score==4):\n",
    "        return \"Positive\"\n",
    "    elif (score==3):\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "    \n",
    "sentiment_data[\"sentiment_label\"]=sentiment_data[\"reviews.rating\"].apply(sentiment_labeler)\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare train, test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split_data=StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n",
    "for tr_indx, ts_indx in split_data.split(sentiment_data, sentiment_data[\"reviews.rating\"]):\n",
    "    train_data=sentiment_data.reindex(tr_indx)\n",
    "    test_data=sentiment_data.reindex(ts_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up stanfordcorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A class to parse chunk data\n",
    "import nltk\n",
    "class Chunker():\n",
    "\tdef __init__(self, n):\n",
    "\t\t# Load the corpus to train the chunk tagger\n",
    "\t\tconll = nltk.corpus.conll2000.chunked_sents()\n",
    "\t\ttreebank = nltk.corpus.treebank_chunk.chunked_sents()\n",
    "\t\tdata = conll + treebank\n",
    "\n",
    "\t\tchunks = [ nltk.chunk.tree2conlltags(tree) for tree in data ]\n",
    "\t\tchunks = [ [(tag[1], tag[2]) for tag in tags] for tags in chunks ]\n",
    "\n",
    "\t\ttrain_chunks = chunks\n",
    "\n",
    "\t\t# Train the chunk tagger\n",
    "\t\tself.chunk_tagger = None\n",
    "\t\tif n == \"Unigram\":\n",
    "\t\t\tself.chunk_tagger = nltk.tag.UnigramTagger(train_chunks)\n",
    "\t\telif n == \"Bigram\":\n",
    "\t\t\tself.chunk_tagger = nltk.tag.BigramTagger(train_chunks)\n",
    "\t\telif n == \"Trigram\":\n",
    "\t\t\tself.chunk_tagger = nltk.tag.TrigramTagger(train_chunks)\n",
    "\t\telse:\n",
    "\t\t\tchunker = nltk.tag.UnigramTagger(train_chunks)\n",
    "\t\t\tchunker = nltk.tag.BigramTagger(train_chunks, backoff=chunker)\n",
    "\t\t\tchunker = nltk.tag.TrigramTagger(train_chunks, backoff=chunker)\n",
    "\t\t\tself.chunk_tagger = chunker\n",
    "\n",
    "\tdef parseTree(self, tokens):\n",
    "\t\t# Gather the words, tags, and chunks\n",
    "\t\twords = [w for (w,t) in tokens]\n",
    "\t\ttags = [t for (w,t) in tokens]\n",
    "\t\tchunks = self.chunk_tagger.tag(tags)\n",
    "\n",
    "\t\t# Sanity check\n",
    "\t\tassert len(words) == len(tags)\n",
    "\t\tassert len(words) == len(chunks)\n",
    "\n",
    "\t\t# Build the parse tree\n",
    "\t\tl = []\n",
    "\t\tfor i in range(0,len(words)):\n",
    "\t\t\tif chunks[i][1]:\n",
    "\t\t\t\tl.append( ' '.join([words[i], tags[i], chunks[i][1]]) )\n",
    "\n",
    "\t\treturn nltk.chunk.conllstr2tree('\\n'.join(l))\n",
    "\n",
    "def chunkLabels(tree):\n",
    "\tl = []\n",
    "\tfor t in tree.subtrees():\n",
    "\t\tif t.label() != 'S':\n",
    "\t\t\tl.append(t.label())\n",
    "\treturn ' '.join(l)\n",
    "\n",
    "ch_uni = Chunker(\"Unigram\") # Train the chunk tagger\n",
    "ch_bi = Chunker(\"Bigram\") # Train the chunk tagger\n",
    "ch_tri = Chunker(\"Trigram\") # Train the chunk tagger\n",
    "\n",
    "# Helper function\n",
    "def GetChunkVectorsTFIDF(X):\n",
    "    chunks=X.apply(str.split) # Tokenize\n",
    "    chunks=chunks.apply(nltk.pos_tag) # POS tag\n",
    "    chunks=chunks.apply(ch_uni.parseTree) # Generate parse tree\n",
    "    chunks=chunks.apply(chunkLabels) # Extract chunk labels\n",
    "    chunks=CountVectorizer().fit_transform(chunks)\n",
    "    chunks=TfidfTransformer().fit_transform(chunks)\n",
    "    return chunks\n",
    "\n",
    "def GetChunkVectorsCount(X):\n",
    "    chunks=X.apply(str.split) # Tokenize\n",
    "    chunks=chunks.apply(nltk.pos_tag) # POS tag\n",
    "    chunks=chunks.apply(ch_uni.parseTree) # Generate parse tree\n",
    "    chunks=chunks.apply(chunkLabels) # Extract chunk labels\n",
    "    chunks=CountVectorizer().fit_transform(chunks)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper function to extract pos tag features\n",
    "\n",
    "def extract_POS(statements):\n",
    "    print('Extracting POS Tags')\n",
    "    pos_tags = POS_tagging(statements,return_word_tag_pairs=False)\n",
    "    bigrams_pos = POS_groupping(pos_tags, grams=2)\n",
    "    trigrams_pos =POS_groupping(pos_tags, grams=3)\n",
    "    print('Finished')\n",
    "    return pos_tags,bigrams_pos,trigrams_pos\n",
    "\n",
    "##\n",
    "def POS_tagging(statements, return_word_tag_pairs = False):\n",
    "    core_nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "    print(\"NLP_Task ready to use.\")\n",
    "    POS_tags = list()\n",
    "    for statement in statements:\n",
    "        statement_tags = list()\n",
    "        annotations = core_nlp.annotate(statement, properties={\n",
    "            'annotators': 'tokenize,pos',\n",
    "            'outputFormat': 'json'\n",
    "            })\n",
    "        for output in annotations['sentences']:\n",
    "            statement_tags.append('<s>')\n",
    "            previous = ''\n",
    "            for token in output['tokens']:\n",
    "                if return_word_tag_pairs:\n",
    "                    statement_tags.append(token['word']+'/'+token['pos'])\n",
    "                else:\n",
    "                    statement_tags.append(token['pos'])\n",
    "\n",
    "        POS_tags.append(statement_tags)\n",
    "    return POS_tags\n",
    "\n",
    "## \n",
    "def POS_groupping(sentences_pos,grams=1):\n",
    "    result = list()\n",
    "    for sentence_tags in sentences_pos:\n",
    "        tag_group = list()\n",
    "        for index, each_tag in enumerate(sentence_tags):\n",
    "            if index < len(sentence_tags)-grams and len(sentence_tags)>=grams:\n",
    "                format_str = str()\n",
    "                for i in range(0,grams):\n",
    "                    format_str += sentence_tags[index+i]\n",
    "                    if i<grams-1:\n",
    "                        format_str += '_'\n",
    "                tag_group.append(format_str)\n",
    "        result.append(tag_group)\n",
    "    return result\n",
    "\n",
    "##\n",
    "def RemoveConsecutiveTags(list_to_remove, postags,ignore_punctuation=False):\n",
    "    withoutConsecutiveTags = list()\n",
    "    for each_tag in postags:\n",
    "        removed = list()\n",
    "        previous = ''\n",
    "        for tt in each_tag:\n",
    "            if tt != previous:\n",
    "                if not ignore_punctuation:\n",
    "                    removed.append(tt)\n",
    "                elif tt not in string.punctuation:\n",
    "                    removed.append(tt)\n",
    "                previous = tt\n",
    "            elif tt not in list_to_remove:\n",
    "                removed.append(tt)\n",
    "                previous = tt\n",
    "        withoutConsecutiveTags.append(removed)\n",
    "    return withoutConsecutiveTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting POS Tags\n",
      "NLP_Task ready to use.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Check whether you have started the CoreNLP server e.g.\n$ cd stanford-corenlp-full-2015-12-09/ \n$ java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x11e83c710>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    719\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11e83c710>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycorenlp/corenlp.py\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(self, text, properties)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=9000): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11e83c710>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6fc6004d8df5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## extracting pos-tag features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munigram_pos_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams_pos_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrigram_pos_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_POS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0munigram_pos_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbigrams_pos_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrigram_pos_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_POS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dd6ec106804e>\u001b[0m in \u001b[0;36mextract_POS\u001b[0;34m(statements)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_POS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting POS Tags'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpos_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOS_tagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_word_tag_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbigrams_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOS_groupping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrigrams_pos\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mPOS_groupping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dd6ec106804e>\u001b[0m in \u001b[0;36mPOS_tagging\u001b[0;34m(statements, return_word_tag_pairs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         annotations = core_nlp.annotate(statement, properties={\n\u001b[1;32m     19\u001b[0m             \u001b[0;34m'annotators'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'tokenize,pos'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'outputFormat'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             })\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pycorenlp/corenlp.py\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(self, text, properties)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             raise Exception('Check whether you have started the CoreNLP server e.g.\\n'\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;34m'$ cd stanford-corenlp-full-2015-12-09/ \\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             '$ java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer')\n",
      "\u001b[0;31mException\u001b[0m: Check whether you have started the CoreNLP server e.g.\n$ cd stanford-corenlp-full-2015-12-09/ \n$ java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer"
     ]
    }
   ],
   "source": [
    "## extracting pos-tag features\n",
    "unigram_pos_tr, bigrams_pos_tr, trigram_pos_tr = extract_POS(statements=train_data['reviews.text'])\n",
    "unigram_pos_ts, bigrams_pos_ts, trigram_pos_ts = extract_POS(statements=test_data['reviews.text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove duplicated pos tag\n",
    "\n",
    "# For review data\n",
    "list_to_remove = ['NNP','CD']\n",
    "\n",
    "removed_pos_tr =RemoveConsecutiveTags(list_to_remove,unigram_pos)\n",
    "removed_pos_bigrams_tr = POS_groupping(grams=2,sentences_pos=removed_pos_tr)\n",
    "removed_pos_trigrams_tr = POS_groupping(grams=3,sentences_pos=removed_pos_tr)\n",
    "\n",
    "removed_pos_ts =RemoveConsecutiveTags(list_to_remove,unigram_pos)\n",
    "removed_pos_bigrams_ts = POS_groupping(grams=2,sentences_pos=removed_pos_ts)\n",
    "removed_pos_trigrams_ts = POS_groupping(grams=3,sentences_pos=removed_pos_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_feats= pd.DataFrame()\n",
    "sentiment_feats['reviews'] = sentiment_data['reviews.text']\n",
    "\n",
    "list_to_remove = ['NNP','CD']\n",
    "sentiment_feats['pos_unig_tr'] = [\" \".join(x).replace('<s>','').replace('$','dollar').strip() for x in removed_pos_tr]\n",
    "sentiment_feats['pos_big_tr'] = [\" \".join(x).replace('$','dollar').strip() for x in removed_pos_bigrams_tr]\n",
    "sentiment_feats['pos_trig_tr'] = [\" \".join(x).replace('$','dollar').strip() for x in removed_pos_trigrams_tr]\n",
    "sentiment_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def GetFeaturesFromPOS(training_data, user_defined_vocabulary=None):\n",
    "    user_defined_vocabulary = [x.lower().replace('$','dollar') for x in user_defined_vocabulary]\n",
    "\n",
    "    # making string of the data\n",
    "    training_str = [\" \".join(x) for x in training_data]\n",
    "\n",
    "    #replace $ by dollar\n",
    "    training_str = [x.replace('$', 'dollar').replace('<s>','sos') for x in training_str]\n",
    "\n",
    "    # features using binary iformation\n",
    "    oneHotVectorizer = CountVectorizer(vocabulary=user_defined_vocabulary,binary=True)\n",
    "    tr_onehot = oneHotVectorizer.fit_transform(training_str).toarray()\n",
    "    print(oneHotVectorizer.vocabulary_)\n",
    "\n",
    "    # features using no-binary information (counting)\n",
    "    countVectorizer = CountVectorizer(vocabulary=user_defined_vocabulary,binary=True)\n",
    "    tr_count = countVectorizer.fit_transform(training_str).toarray()\n",
    "\n",
    "    # features using tf-idf vectors\n",
    "    tfIdfVectorizer = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "    tr_tfidf = tfIdfVectorizer.fit_transform(tr_count)\n",
    "\n",
    "    return tr_onehot, tr_count, tr_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_relevant_unigrams =  ['VBZ', 'DT', 'NNPS', 'VBP', 'JJ', 'IN', 'WRB', 'VBD', 'PRP', 'RP', 'WDT', 'VB', 'NNP', 'VBG', 'PRP$', 'VBN', 'CD', 'RB', 'WP', 'JJS', 'JJR', 'EX', 'RBS', 'FW', 'LS'] \n",
    "amazonRev_onehot_unigram_tr, amazonRev_count_unigram_tr, amazonRev_tfidf_unigram_tr = GetFeaturesFromPOS(training_data=removed_pos_tr, user_defined_vocabulary=pos_relevant_unigrams)\n",
    "\n",
    "pos_relevant_bigrams = ['NNPS_VBP', 'VB_NNP', 'IN_DT', 'VB_JJ', 'JJ_CD', 'CD_NNS', 'DT_JJS', 'JJR_IN', 'IN_CD', 'CC_IN', 'RB_VBD', 'CD_NN', 'NN_TO', 'JJR_JJ', 'VB_CD'] \n",
    "amazonRev_onehot_bigram_tr, amazonRev_count_bigram_tr, amazonRev_tfidf_bigram_tr = GetFeaturesFromPOS(training_data=removed_pos_bigrams_tr, user_defined_vocabulary=pos_relevant_bigrams)\n",
    "\n",
    "pos_relevant_trigrams = ['VBD_VBN_IN', 'IN_DT_JJ', 'CD_NN_IN', 'IN_CD_NNS', 'IN_DT_NN', 'DT_JJ_CD', 'MD_VB_IN', 'JJS_JJ_NN', 'CC_JJ_NNS', 'JJ_NNS_VBP', 'VBP_CD_NN', 'sos_JJR_IN', 'IN_DT_NNS','JJ_NN_MD']\n",
    "amazonRev_onehot_trigram_tr, amazonRev_count_trigram_tr, amazonRev_tfidf_trigram_tr = GetFeaturesFromPOS(training_data=removed_pos_trigrams_tr, user_defined_vocabulary=pos_relevant_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(amazonRev_onehot_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(amazonRev_onehot_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(amazonRev_onehot_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_feats['pos_unigrams_1hot_tr'] =  [str(x) for x in amazonRev_onehot_unigram_tr]\n",
    "sentiment_feats['pos_bigrams_1hot_tr'] = [str(x) for x in amazonRev_onehot_bigram_tr]\n",
    "sentiment_feats['pos_trigrams_1hot_tr'] = [str(x) for x in amazonRev_onehot_trigram_tr]\n",
    "\n",
    "sentiment_feats['pos_unigrams_count_tr'] =  [str(x) for x in amazonRev_count_unigram_tr]\n",
    "sentiment_feats['pos_bigrams_count_tr'] = [str(x) for x in amazonRev_count_bigram_tr]\n",
    "sentiment_feats['pos_trigrams_count_tr'] = [str(x) for x in amazonRev_count_trigram_tr]\n",
    "\n",
    "sentiment_feats['pos_unigrams_tfidf_tr'] =  [str(x) for x in amazonRev_tfidf_unigram_tr]\n",
    "sentiment_feats['pos_bigrams_tfidf_tr'] = [str(x) for x in amazonRev_tfidf_bigram_tr]\n",
    "sentiment_feats['pos_trigrams_tfidf_tr'] = [str(x) for x in amazonRev_tfidf_trigram_tr]\n",
    "\n",
    "sentiment_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentiment_feats['chunks_tfidf_tr'] = GetChunkVectorsTFIDF(train_data['reviews.text'])\n",
    "sentiment_feats['chunks_count_tr'] = GetChunkVectorsCount(train_data['reviews.text'])\n",
    "\n",
    "sentiment_feats['chunks_tfidf_ts'] = GetChunkVectorsTFIDF(test_data['reviews.text'])\n",
    "sentiment_feats['chunks_count_ts'] = GetChunkVectorsCount(test_data['reviews.text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train ML classifier\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(sentiment_feats[['pos_unigrams_1hot_tr', 'pos_unigrams_count_tr', 'pos_unigrams_tfidf_tr', 'chunks_tfidf_tr']])\n",
    "#predicted_nb = nb.predict( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use different features\n",
    "\n",
    "unigram_pos_str = [\" \".join(x) for x in unigram_pos]\n",
    "bigram_pos_str = [\" \".join(x) for x in bigrams_pos]\n",
    "trigram_pos_str = [\" \".join(x) for x in trigram_pos]\n",
    "\n",
    "cv_uni = CountVectorizer()\n",
    "pos_uni_feats = cv_uni.fit_transform(unigram_pos_str).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "\n",
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('conll2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTextBlobFeatures(corpus):\n",
    "    extractor = ConllExtractor()\n",
    "    text_blob_features = np.zeros((len(corpus),4))\n",
    "    blob_sentiment_analyzer = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "    for i,each_text in enumerate(corpus):\n",
    "        text_blob_features[i,0]=blob_sentiment_analyzer(each_text).sentiment[1]\n",
    "        text_blob_features[i,1]=blob_sentiment_analyzer(each_text).sentiment[2]\n",
    "        text_blob_features[i,2]= TextBlob(each_text).subjectivity\n",
    "        noun_phrase_extractor = TextBlob(each_text, np_extractor=extractor)\n",
    "        text_blob_features[i,3]= len(noun_phrase_extractor.noun_phrases)\n",
    "    return text_blob_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_data['reviews.text']\n",
    "y_train=train_data[\"sentiment_label\"]\n",
    "X_test=test_data[\"reviews.text\"]\n",
    "y_test=test_data[\"sentiment_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_tb_features = extractTextBlobFeatures(X_train)\n",
    "Xte_tb_features = extractTextBlobFeatures(X_test)\n",
    "ytr_tb_features = extractTextBlobFeatures(y_train)\n",
    "yte_tb_features = extractTextBlobFeatures(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_tb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtr= np.array(Xtr_tb_features.ravel(),)\n",
    "# ytr=np.array(ytr_tb_features.ravel(),)\n",
    "\n",
    "# Xte = np.array(Xte_tb_features.ravel(),)\n",
    "# yte = np.array(yte_tb_features.ravel(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## use multinomial NB classifier\n",
    "# clf_multiNB_pipe = Pipeline([(\"vect\", CountVectorizer()), (\"tfidf\", TfidfTransformer()), (\"clf_nominalNB\", MultinomialNB())])\n",
    "# clf_multiNB_pipe.fit(Xtr, ytr)\n",
    "# predicted_nb = clf_multiNB_pipe.predict(Xte)\n",
    "# print(\"accuracy metrics for training naive bayes classifier:\\n\",metrics.classification_report(yte, predicted_nb, target_names = ['1','0','-1']))\n",
    "# print(\"======================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte_tb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr_tb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
